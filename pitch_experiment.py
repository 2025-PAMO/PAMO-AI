from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from transformers import AutoProcessor, MusicgenForConditionalGeneration
import librosa
import torchaudio
import torch
import tempfile
import os
import io
import numpy as np
import logging

# â”€â”€ ë¡œê¹… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("pitch_experiment")

# â”€â”€ ì•± & CORS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI(title="MusicGen (Pitch-only)")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],      # í•„ìš”ì‹œ íŠ¹ì • ì˜¤ë¦¬ì§„ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€ ëª¨ë¸ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SAMPLE_RATE = 32000
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

logger.info("ğŸµ MusicGen ëª¨ë¸ ë¡œë“œ ì¤‘...")
processor = AutoProcessor.from_pretrained("facebook/musicgen-small")
model = MusicgenForConditionalGeneration.from_pretrained("facebook/musicgen-small").to(DEVICE)
model.eval()
logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device=%s)", DEVICE)

# â”€â”€ Pitch ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_pitches(file_path: str, max_notes: int = 30) -> list[str]:
    y, sr = librosa.load(file_path, sr=SAMPLE_RATE)
    pitches, _ = librosa.piptrack(y=y, sr=sr)
    seq = []
    for frame in pitches.T:
        idx = int(np.argmax(frame))
        pitch = float(frame[idx])
        if pitch > 0:
            note = librosa.hz_to_note(pitch)
            seq.append(note)
            if len(seq) >= max_notes:
                break
    return seq

# â”€â”€ ìœ í‹¸: í…ì„œë¥¼ WAV ë°”ì´íŠ¸ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _to_wav_bytes(audio_tensor: torch.Tensor) -> io.BytesIO:
    if audio_tensor.dim() == 1:
        audio_tensor = audio_tensor.unsqueeze(0)  # (1, samples)
    buffer = io.BytesIO()
    torchaudio.save(buffer, audio_tensor.cpu(), sample_rate=SAMPLE_RATE, format="wav")
    buffer.seek(0)
    return buffer

# â”€â”€ í”¼ì¹˜ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ + í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/generate-music-pitch-only")
async def generate_music_with_pitch(file: UploadFile = File(...), prompt: str = Form(...)):
    if not file:
        raise HTTPException(status_code=400, detail="fileì´ í•„ìš”í•©ë‹ˆë‹¤.")
    logger.info("ğŸ“© [pitch-only] í”„ë¡¬í”„íŠ¸='%s' | íŒŒì¼=%s", prompt, getattr(file, "filename", ""))

    # ì—…ë¡œë“œë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        tmp.write(await file.read())
        tmp_path = tmp.name

    try:
        # í”¼ì¹˜ â†’ ìŒí‘œ ì‹œí€€ìŠ¤
        pitch_tokens = extract_pitches(tmp_path)
        pitch_str = " ".join(pitch_tokens) if pitch_tokens else "C4"

        # ìµœì¢… í”„ë¡¬í”„íŠ¸
        full_prompt = f"melody: {pitch_str}. style: {prompt}"
        logger.info("ğŸ¯ ìµœì¢… í”„ë¡¬í”„íŠ¸: %s", full_prompt)

        # MusicGen ì¶”ë¡ 
        inputs = processor(text=[full_prompt], return_tensors="pt")
        inputs = {k: v.to(DEVICE) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}
        logger.info("ğŸ§  ëª¨ë¸ ì¶”ë¡  ì‹œì‘ (pitch+text)")
        with torch.no_grad():
            output = model.generate(
                **inputs,
                do_sample=True,
                guidance_scale=1.5,
                max_new_tokens=512,
            )

        buffer = _to_wav_bytes(output[0].detach())
        return StreamingResponse(buffer, media_type="audio/wav")
    except Exception as e:
        logger.exception("í”¼ì¹˜ ê¸°ë°˜ ìƒì„± ì‹¤íŒ¨: %s", e)
        return JSONResponse(status_code=500, content={"error": str(e)})
    finally:
        try:
            os.remove(tmp_path)
        except Exception:
            pass

# â”€â”€ í˜¸í™˜ìš© ì—”ë“œí¬ì¸íŠ¸: /generate-music â†’ Aì•ˆ ë§¤í•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/generate-music")
async def generate_music_compat(file: UploadFile = File(...), prompt: str = Form(...)):
    return await generate_music_with_pitch(file=file, prompt=prompt)

# â”€â”€ ë¡œì»¬ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("pitch_experiment:app", host="0.0.0.0", port=8010, reload=True)

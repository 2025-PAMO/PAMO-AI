import io
import os
import tempfile
import logging
from typing import List

import torch
import torchaudio
import librosa
from pydub import AudioSegment
from fastapi import UploadFile
import numpy as np
from transformers import AutoProcessor, MusicgenForConditionalGeneration
# -------------------------------------------------


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

SR = 32000
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

OUTPUT_DIR = os.getenv("OUTPUT_DIR", "./outputs")
os.makedirs(OUTPUT_DIR, exist_ok=True)

logger.info("ğŸµ MusicGen ëª¨ë¸ ë¡œë“œ ì¤‘...")
processor = AutoProcessor.from_pretrained("facebook/musicgen-small")
model = MusicgenForConditionalGeneration.from_pretrained("facebook/musicgen-small").to(DEVICE)
model.eval()
logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device=%s)", DEVICE)


# -------------------------------------------------
# ìœ í‹¸: í”¼ì¹˜(ìŒë†’ì´) ì‹œí€€ìŠ¤ ì¶”ì¶œ
# -------------------------------------------------
def extract_pitches(file_path: str, max_notes: int = 30) -> List[str]:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ í”¼ì¹˜ë¥¼ ì¶”ì¶œí•´ ìŒí‘œ ì‹œí€€ìŠ¤ë¡œ ë°˜í™˜.
    ë„ˆë¬´ ê¸¸ì–´ì§€ëŠ” ê±¸ ë°©ì§€í•˜ê¸° ìœ„í•´ max_notes ë§Œí¼ë§Œ ì‚¬ìš©.
    """
    y, sr = librosa.load(file_path, sr=SR, mono=True)
    pitches, _ = librosa.piptrack(y=y, sr=sr)
    notes: List[str] = []
    for frame in pitches.T:
        idx = int(frame.argmax())
        freq = float(frame[idx])
        if freq > 0:
            notes.append(librosa.hz_to_note(freq))
        if len(notes) >= max_notes:
            break
    return notes


# -------------------------------------------------
# ë©”ì¸: ì—…ë¡œë“œ íŒŒì¼ + í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ìŒì•… ìƒì„±
# -------------------------------------------------
async def generate_music_file(file: UploadFile, prompt: str, repeat_count: int = 4) -> str:
    """
    ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ì—ì„œ í”¼ì¹˜ë¥¼ ì¶”ì¶œí•´ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ í™•ì¥í•˜ê³ ,
    MusicGenìœ¼ë¡œ ìŒì•…ì„ ìƒì„±í•œ ë’¤, crossfade ë°˜ë³µì„ ì ìš©í•´ ìµœì¢… wav íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜.
    """
    try:
        # 1) ì—…ë¡œë“œ íŒŒì¼ì„ ì„ì‹œ ê²½ë¡œì— ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            raw = await file.read()
            tmp.write(raw)
            tmp_path = tmp.name
        logger.info("ğŸ“¥ ì—…ë¡œë“œ íŒŒì¼ ì €ì¥: %s", tmp_path)

        # 2) í”¼ì¹˜ ì¶”ì¶œ â†’ í”„ë¡¬í”„íŠ¸ í™•ì¥
        pitch_tokens = extract_pitches(tmp_path)
        pitch_str = " ".join(pitch_tokens) if pitch_tokens else "none"
        full_prompt = f"melody: {pitch_str}. style: {prompt}"
        logger.info("ğŸ¯ ìµœì¢… í”„ë¡¬í”„íŠ¸: %s", full_prompt)

        # 3) ëª¨ë¸ ì…ë ¥ êµ¬ì„±
        inputs = processor(text=[full_prompt], return_tensors="pt")
        inputs = {k: (v.to(DEVICE) if isinstance(v, torch.Tensor) else v) for k, v in inputs.items()}

        # 4) ëª¨ë¸ ì¶”ë¡ 
        logger.info("ğŸ§  ëª¨ë¸ ì¶”ë¡  ì‹œì‘")
        with torch.no_grad():
            output = model.generate(
                **inputs,
                do_sample=True,
                guidance_scale=1.5,
                max_new_tokens=512,
            )

        # MusicGenì€ wave tensorë¥¼ ë°˜í™˜í•œë‹¤ëŠ” ê°€ì •
        audio = output[0]  # [channels, time] ë˜ëŠ” [time]
        if audio.dim() == 1:
            audio = audio.unsqueeze(0)  # [1, time]

        # 5) ì›ë³¸ íŒŒì¼ ì €ì¥
        raw_path = os.path.join(OUTPUT_DIR, "generated_raw.wav")
        torchaudio.save(raw_path, audio.cpu(), sample_rate=SR, format="wav")
        logger.info("ğŸ’¾ ì›ë³¸ ì €ì¥ ì™„ë£Œ: %s", raw_path)

        # 6) crossfade ë°˜ë³µ(ê¸°ë³¸ 4íšŒ)
        segment = AudioSegment.from_file(raw_path, format="wav")
        looped = segment
        for _ in range(max(1, repeat_count) - 1):
            looped = looped.append(segment, crossfade=100)

        logger.info(
            "ğŸ” ë°˜ë³µ ì ìš©: %.1fs Ã— %d = %.1fs",
            len(segment) / 1000.0, max(1, repeat_count), len(looped) / 1000.0
        )

        # 7) ìµœì¢… íŒŒì¼ ì €ì¥
        final_path = os.path.join(OUTPUT_DIR, "generated_music_looped.wav")
        looped.export(final_path, format="wav")
        logger.info("âœ… ìµœì¢… íŒŒì¼ ì €ì¥ ì™„ë£Œ: %s", final_path)

        # ì„ì‹œíŒŒì¼ ì •ë¦¬
        try:
            os.remove(tmp_path)
        except Exception:
            pass

        return final_path

    except Exception as e:
        logger.exception("âŒ ìŒì•… ìƒì„± ì‹¤íŒ¨: %s", str(e))
        raise RuntimeError("ìŒì•… ìƒì„± ì‹¤íŒ¨") from e

from fastapi import UploadFile
import torchaudio
import torch
import os
import numpy as np
from transformers import AutoProcessor, MusicgenForConditionalGeneration
from pydub import AudioSegment
import tempfile
import logging
import librosa

logger = logging.getLogger(__name__)

# ëª¨ë¸ ì¤€ë¹„
processor = AutoProcessor.from_pretrained("facebook/musicgen-small")
model = MusicgenForConditionalGeneration.from_pretrained("facebook/musicgen-small")

OUTPUT_DIR = "output"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ğŸ¼ Pitch ì¶”ì¶œ í•¨ìˆ˜
def extract_pitches(file_path):
    y, sr = librosa.load(file_path, sr=32000)
    pitches, _ = librosa.piptrack(y=y, sr=sr)
    pitch_sequence = []
    for frame in pitches.T:
        idx = frame.argmax()
        pitch = frame[idx]
        if pitch > 0:
            note = librosa.hz_to_note(pitch)
            pitch_sequence.append(note)
    return pitch_sequence[:30]  # ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©

# ğŸ¶ ë©”ì¸ í•¨ìˆ˜
async def generate_music_file(file: UploadFile, prompt: str) -> str:
    sr = 32000
    try:
        # 1) ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ wavë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(await file.read())
            tmp_path = tmp.name

        # 2) í”¼ì¹˜ ì¶”ì¶œ â†’ í”„ë¡¬í”„íŠ¸ í™•ì¥
        pitch_tokens = extract_pitches(tmp_path)
        pitch_str = " ".join(pitch_tokens)
        full_prompt = f"melody: {pitch_str}. style: {prompt}"
        logger.info("ğŸ¯ ìµœì¢… í”„ë¡¬í”„íŠ¸: %s", full_prompt)

        # 3) ëª¨ë¸ ì…ë ¥ êµ¬ì„±
        inputs = processor(text=[full_prompt], return_tensors="pt")

        # 4) ëª¨ë¸ ì¶”ë¡ 
        logger.info("ğŸ§  ëª¨ë¸ ì¶”ë¡  ì‹œì‘")
        output = model.generate(
            **inputs,
            do_sample=True,
            guidance_scale=1.5,
            max_new_tokens=512
        )

        output_tensor = output[0]
        if output_tensor.dim() == 1:
            output_tensor = output_tensor.unsqueeze(0)

        # 5) ì›ë³¸ íŒŒì¼ë¡œ ì €ì¥
        raw_path = os.path.join(OUTPUT_DIR, "generated_raw.wav")
        torchaudio.save(raw_path, output_tensor, sample_rate=sr)
        logger.info(f"ğŸ’¾ ì›ë³¸ ì €ì¥ ì™„ë£Œ: {raw_path}")

        # 6) ê³ ì • 4íšŒ ë°˜ë³µ
        segment = AudioSegment.from_wav(raw_path)
        REPEAT_COUNT = 4

        looped = segment
        for _ in range(REPEAT_COUNT - 1):
            looped = looped.append(segment, crossfade=100)

        logger.info(f"ğŸ” ì „ì²´ {REPEAT_COUNT}íšŒ ë°˜ë³µ ì™„ë£Œ "
                    f"({len(segment)/1000:.1f}ì´ˆ Ã— {REPEAT_COUNT} = {len(looped)/1000:.1f}ì´ˆ)")

        # 7) ìµœì¢… ì €ì¥
        final_path = os.path.join(OUTPUT_DIR, "generated_music_looped.wav")
        looped.export(final_path, format="wav")
        logger.info(f"âœ… ìµœì¢… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {final_path}")

        # ì„ì‹œíŒŒì¼ ì‚­ì œ
        os.remove(tmp_path)

        return final_path

    except Exception as e:
        logger.exception("âŒ ìŒì•… ìƒì„± ì‹¤íŒ¨: %s", str(e))
        raise RuntimeError("ìŒì•… ìƒì„± ì‹¤íŒ¨")

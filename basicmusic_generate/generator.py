import io
import os
import tempfile
import logging
from typing import List

import torch
import torchaudio
import librosa
from pydub import AudioSegment
from fastapi import UploadFile
import numpy as np
from transformers import AutoProcessor, MusicgenForConditionalGeneration

# -------------------------------------------------
# ë¡œê¹… ì„¤ì •
# -------------------------------------------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

SR = 32000
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

OUTPUT_DIR = os.getenv("OUTPUT_DIR", "./outputs")
os.makedirs(OUTPUT_DIR, exist_ok=True)

logger.info("ğŸµ MusicGen ëª¨ë¸ ë¡œë“œ ì¤‘...")
processor = AutoProcessor.from_pretrained("facebook/musicgen-small")
model = MusicgenForConditionalGeneration.from_pretrained("facebook/musicgen-small").to(DEVICE)
model.eval()
logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device=%s)", DEVICE)


# -------------------------------------------------
# ìœ í‹¸: í”¼ì¹˜(ìŒë†’ì´) ì‹œí€€ìŠ¤ ì¶”ì¶œ
# -------------------------------------------------
def extract_pitches(file_path: str, max_notes: int = 30) -> List[str]:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ í”¼ì¹˜ë¥¼ ì¶”ì¶œí•´ ìŒí‘œ ì‹œí€€ìŠ¤ë¡œ ë°˜í™˜.
    ë„ˆë¬´ ê¸¸ì–´ì§€ëŠ” ê±¸ ë°©ì§€í•˜ê¸° ìœ„í•´ max_notes ë§Œí¼ë§Œ ì‚¬ìš©.
    """
    y, sr = librosa.load(file_path, sr=SR, mono=True)
    pitches, _ = librosa.piptrack(y=y, sr=sr)
    notes: List[str] = []
    for frame in pitches.T:
        idx = int(frame.argmax())
        freq = float(frame[idx])
        if freq > 0:
            notes.append(librosa.hz_to_note(freq))
        if len(notes) >= max_notes:
            break
    return notes


# -------------------------------------------------
# ë©”ì¸: ì—…ë¡œë“œ íŒŒì¼(Optional) + í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ìŒì•… ìƒì„±
# -------------------------------------------------
async def generate_music_file(file: UploadFile | None, prompt: str, repeat_count: int = 4) -> str:
    """
    ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ê°€ ìˆìœ¼ë©´ í”¼ì¹˜ë¥¼ ì¶”ì¶œí•´ í”„ë¡¬í”„íŠ¸ í™•ì¥,
    ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©.
    MusicGenìœ¼ë¡œ ìŒì•…ì„ ìƒì„±í•˜ê³  crossfade ë°˜ë³µì„ ì ìš©í•œ wav íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜.
    """
    try:
        tmp_path = None
        pitch_str = "none"

        # 1) ì—…ë¡œë“œ íŒŒì¼ ì²˜ë¦¬ (ìˆì„ ê²½ìš°ë§Œ)
        if file is not None:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                raw = await file.read()
                tmp.write(raw)
                tmp_path = tmp.name
            logger.info("ğŸ“¥ ì—…ë¡œë“œ íŒŒì¼ ì €ì¥: %s", tmp_path)

            # í”¼ì¹˜ ì¶”ì¶œ
            pitch_tokens = extract_pitches(tmp_path)
            pitch_str = " ".join(pitch_tokens) if pitch_tokens else "none"
            logger.info("ğŸ¹ í”¼ì¹˜ ì¶”ì¶œ ì™„ë£Œ: %s", pitch_str)

        # 2) ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        full_prompt = f"melody: {pitch_str}. style: {prompt}"
        logger.info("ğŸ¯ ìµœì¢… í”„ë¡¬í”„íŠ¸: %s", full_prompt)

        # 3) ëª¨ë¸ ì…ë ¥ êµ¬ì„±
        inputs = processor(text=[full_prompt], return_tensors="pt")
        inputs = {k: (v.to(DEVICE) if isinstance(v, torch.Tensor) else v) for k, v in inputs.items()}

        # 4) ëª¨ë¸ ì¶”ë¡ 
        logger.info("ğŸ§  ëª¨ë¸ ì¶”ë¡  ì‹œì‘")
        with torch.no_grad():
            output = model.generate(
                **inputs,
                do_sample=True,
                guidance_scale=1.5,
                max_new_tokens=512,
            )

        # MusicGenì€ wave tensor ë°˜í™˜í•œë‹¤ê³  ê°€ì •
        audio = output[0]  # [channels, time] or [time]
        if audio.dim() == 1:
            audio = audio.unsqueeze(0)  # [1, time]

        # 5) ì›ë³¸ ì €ì¥
        raw_path = os.path.join(OUTPUT_DIR, "generated_raw.wav")
        torchaudio.save(raw_path, audio.cpu(), sample_rate=SR, format="wav")
        logger.info("ğŸ’¾ ì›ë³¸ ì €ì¥ ì™„ë£Œ: %s", raw_path)

        # 6) crossfade ë°˜ë³µ
        segment = AudioSegment.from_file(raw_path, format="wav")
        looped = segment
        for _ in range(max(1, repeat_count) - 1):
            looped = looped.append(segment, crossfade=100)

        logger.info("ğŸ” ë°˜ë³µ ì ìš©: %.1fs Ã— %d = %.1fs",
            len(segment) / 1000.0, max(1, repeat_count), len(looped) / 1000.0
        )

        # 7) ìµœì¢… ì €ì¥
        final_path = os.path.join(OUTPUT_DIR, "generated_music_looped.wav")
        looped.export(final_path, format="wav")
        logger.info("âœ… ìµœì¢… íŒŒì¼ ì €ì¥ ì™„ë£Œ: %s", final_path)

        # ì„ì‹œíŒŒì¼ ì •ë¦¬
        if tmp_path and os.path.exists(tmp_path):
            os.remove(tmp_path)

        return final_path

    except Exception as e:
        logger.exception("âŒ ìŒì•… ìƒì„± ì‹¤íŒ¨: %s", str(e))
        raise RuntimeError("ìŒì•… ìƒì„± ì‹¤íŒ¨") from e

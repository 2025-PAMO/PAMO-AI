# generator.py
import io
import logging
import numpy as np
import torch
import torchaudio
from pydub import AudioSegment
from transformers import AutoProcessor, MusicgenForConditionalGeneration
from fastapi import UploadFile

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

SR = 32000
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

logger.info("ğŸµ MusicGen ëª¨ë¸ ë¡œë“œ ì¤‘...")
processor = AutoProcessor.from_pretrained("facebook/musicgen-small")
model = MusicgenForConditionalGeneration.from_pretrained("facebook/musicgen-small").to(DEVICE)
model.eval()
logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device=%s)", DEVICE)

async def generate_wav(prompt: str, file: UploadFile | None) -> io.BytesIO:
    """
    í”„ë¡¬í”„íŠ¸(+ì„ íƒì  í—ˆë°)ë¥¼ ë°›ì•„ WAV(BytesIO) ìƒì„± í›„ ë°˜í™˜.
    ë°˜í™˜ ë²„í¼ëŠ” headë¡œ ì´ë™(seek(0))ëœ ìƒíƒœ.
    """
    # 1) í—ˆë° ì „ì²˜ë¦¬ (ìˆì„ ë•Œë§Œ)
    melody_wave = None
    if file is not None:
        raw = await file.read()
        if raw:
            seg = AudioSegment.from_file(io.BytesIO(raw))
            seg = seg.set_channels(1).set_frame_rate(SR)
            samples = np.array(seg.get_array_of_samples()).astype(np.float32) / (2 ** 15)
            melody_wave = torch.tensor(samples, dtype=torch.float32).unsqueeze(0).contiguous()

    # 2) ì…ë ¥ êµ¬ì„±
    if melody_wave is not None:
        waveform = melody_wave.squeeze().numpy()
        if waveform.ndim == 2 and waveform.shape[1] == 1:
            waveform = waveform[:, 0]
        inputs = processor(text=[prompt], audio=waveform, sampling_rate=SR, return_tensors="pt")
    else:
        inputs = processor(text=[prompt], return_tensors="pt")

    inputs = {k: v.to(DEVICE) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}

    # 3) ìƒì„±
    with torch.no_grad():
        output = model.generate(
            **inputs,
            do_sample=True,
            guidance_scale=1.5,
            max_new_tokens=512,
        )

    audio = output[0]
    if audio.dim() == 1:
        audio = audio.unsqueeze(0)

    # 4) ì›ë³¸ WAVë¥¼ ë©”ëª¨ë¦¬ ë²„í¼ë¡œ
    raw_buf = io.BytesIO()
    torchaudio.save(raw_buf, audio.cpu(), sample_rate=SR, format="wav")
    raw_buf.seek(0)

    # 5) (ì„ íƒ) ë£¨í”„/í¬ë¡œìŠ¤í˜ì´ë“œ ì²˜ë¦¬ â€” ë©”ëª¨ë¦¬ ë‚´ì—ì„œë§Œ
    seg = AudioSegment.from_file(raw_buf, format="wav")
    duration_ms = len(seg)
    if duration_ms > 5000:
        midpoint = duration_ms // 2
        loop_segment = seg[midpoint:]
        looped = loop_segment
        for _ in range(5):  # ì´ 6ë²ˆ ë°˜ë³µ
            looped = looped.append(loop_segment, crossfade=100)
    else:
        looped = seg

    out_buf = io.BytesIO()
    looped.export(out_buf, format="wav")
    out_buf.seek(0)  # âœ… BytesIOì—ë§Œ seek

    return out_buf
